{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 20newsgroups-BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SRAVANIDHARA/FARO_assignment/blob/master/20newsgroups_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ474pWuFi5e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8d63ffe7-1af8-49ef-dbed-55a6a57e40d6"
      },
      "source": [
        "# install ktrain on Google Colab\n",
        "!pip3 install ktrain"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ktrain in /usr/local/lib/python3.6/dist-packages (0.14.1)\n",
            "Requirement already satisfied: tensorflow==2.1.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.1.0)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.4.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.0.8)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ktrain) (5.5.0)\n",
            "Requirement already satisfied: syntok in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.2.2)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.2.3)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.21.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.22.2.post1)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from ktrain) (20.3)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.1.0)\n",
            "Requirement already satisfied: transformers>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.8.0)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.4)\n",
            "Requirement already satisfied: cchardet in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.1.6)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.0.12)\n",
            "Requirement already satisfied: keras-bert>=0.81.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.81.0)\n",
            "Requirement already satisfied: whoosh in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.7.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.14.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (3.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (3.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.28.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.2.2)\n",
            "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (2.1.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (2.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.18.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.34.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.4.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.9.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (2.8.1)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (2.11.2)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (7.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (3.13)\n",
            "Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (4.5.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (2.1.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (46.1.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.8.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from syntok->ktrain) (2019.12.20)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->ktrain) (19.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->ktrain) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->ktrain) (0.21.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->ktrain) (4.38.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->ktrain) (2.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->ktrain) (0.3.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->ktrain) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->ktrain) (0.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->ktrain) (0.1.85)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->ktrain) (1.12.39)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->ktrain) (0.0.41)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->ktrain) (0.5.2)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->ktrain) (2.3.1)\n",
            "Requirement already satisfied: keras-transformer>=0.30.0 in /usr/local/lib/python3.6/dist-packages (from keras-bert>=0.81.0->ktrain) (0.32.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.7.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0->ktrain) (2.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh->ktrain) (1.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ktrain) (0.1.9)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ktrain) (0.6.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->ktrain) (1.51.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.7.0->ktrain) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.7.0->ktrain) (1.15.39)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.7.0->ktrain) (0.9.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.7.0->ktrain) (7.1.1)\n",
            "Requirement already satisfied: keras-multi-head>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.30.0->keras-bert>=0.81.0->ktrain) (0.22.0)\n",
            "Requirement already satisfied: keras-layer-normalization>=0.12.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.30.0->keras-bert>=0.81.0->ktrain) (0.14.0)\n",
            "Requirement already satisfied: keras-embed-sim>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.30.0->keras-bert>=0.81.0->ktrain) (0.7.0)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.30.0->keras-bert>=0.81.0->ktrain) (0.6.0)\n",
            "Requirement already satisfied: keras-pos-embd>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.30.0->keras-bert>=0.81.0->ktrain) (0.11.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.1.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers>=2.7.0->ktrain) (0.15.2)\n",
            "Requirement already satisfied: keras-self-attention==0.41.0 in /usr/local/lib/python3.6/dist-packages (from keras-multi-head>=0.22.0->keras-transformer>=0.30.0->keras-bert>=0.81.0->ktrain) (0.41.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8hIFvooF4vc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import ktrain and the ktrain.text modules\n",
        "import ktrain\n",
        "from ktrain import text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBQzPRobF7YR",
        "colab_type": "code",
        "outputId": "1036ef5a-1322-4761-cac1-6f3b26ef2cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ktrain.__version__"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.14.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6z1hsqsNJhvi",
        "colab_type": "text"
      },
      "source": [
        "# Multiclass Text Classification Using BERT and Keras\n",
        "In this example, we will use ***ktrain*** ([a lightweight wrapper around Keras](https://github.com/amaiya/ktrain)) to build a model using the dataset employed in the **scikit-learn** tutorial: [Working with Text Data](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html).  As in the tutorial, we will sample 4 newsgroups to create a relatively small multiclass text classification dataset.  The objective is to accurately classify each document into one of these four newsgroup topic categories.  This will provide us an opportunity to see **BERT** in action on a relatively smaller training set.  Let's fetch the [20newsgroups dataset ](http://qwone.com/~jason/20Newsgroups/) using scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O6BKsySFqzL",
        "colab_type": "code",
        "outputId": "cda32a5f-74f7-4e06-ab1a-8ea44329b8a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# fetch the dataset using scikit-learn\n",
        "categories = ['comp.graphics', 'comp.os.ms-windows.misc',\n",
        "             'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale',\n",
        "             'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey',\n",
        "             'talk.politics.misc', 'talk.politics.guns', 'talk.politics.mideast', 'sci.crypt',\n",
        "             'sci.electronics', 'sci.med', 'sci.space', 'talk.religion.misc', 'alt.atheism', 'soc.religion.christian']\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "train_b = fetch_20newsgroups(subset='train',\n",
        "   categories=categories, shuffle=True, random_state=42)\n",
        "test_b = fetch_20newsgroups(subset='test',\n",
        "   categories=categories, shuffle=True, random_state=42)\n",
        "\n",
        "print('size of training set: %s' % (len(train_b['data'])))\n",
        "print('size of validation set: %s' % (len(test_b['data'])))\n",
        "print('classes: %s' % (train_b.target_names))\n",
        "\n",
        "x_train = train_b.data\n",
        "y_train = train_b.target\n",
        "x_test = test_b.data\n",
        "y_test = test_b.target"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of training set: 11314\n",
            "size of validation set: 7532\n",
            "classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBpAFYFFIOSz",
        "colab_type": "text"
      },
      "source": [
        "## STEP 1:  Load and Preprocess the Data\n",
        "Preprocess the data using the `texts_from_array function` (since the data resides in an array).\n",
        "If your documents are stored in folders or a CSV file you can use the `texts_from_folder` or `texts_from_csv` functions, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju2LoLr2FwIb",
        "colab_type": "code",
        "outputId": "ff7a6f7a-2efd-4c65-8c94-2872412c760c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "(x_train,  y_train), (x_test, y_test), preproc = text.texts_from_array(x_train=x_train, y_train=y_train,\n",
        "                                                                       x_test=x_test, y_test=y_test,\n",
        "                                                                       class_names=train_b.target_names,\n",
        "                                                                       preprocess_mode='bert',\n",
        "                                                                       maxlen=350, \n",
        "                                                                       max_features=35000)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task: text classification\n",
            "preprocessing train...\n",
            "language: en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "preprocessing test...\n",
            "language: en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxKHrhP3IVyA",
        "colab_type": "text"
      },
      "source": [
        "## STEP 2:  Load the BERT Model and Instantiate a Learner object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szoSlW1HGKWI",
        "colab_type": "code",
        "outputId": "3fb7ce0a-3871-4e87-aff0-0444b774cd65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# you can disregard the deprecation warnings arising from using Keras 2.2.4 with TensorFlow 1.14.\n",
        "model = text.text_classifier('bert', train_data=(x_train, y_train), preproc=preproc)\n",
        "learner = ktrain.get_learner(model, train_data=(x_train, y_train), batch_size=6)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 350\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x631IAqvIlDg",
        "colab_type": "text"
      },
      "source": [
        "## STEP 3: Train the Model\n",
        "\n",
        "We train using one of the three learning rates recommended in the BERT paper: *5e-5*, *3e-5*, or *2e-5*.\n",
        "Alternatively, the ktrain Learning Rate Finder can be used to find a good learning rate by invoking `learner.lr_find()` and `learner.lr_plot()`, prior to training.\n",
        "The `learner.fit_onecycle` method employs a [1cycle learning rate policy](https://arxiv.org/pdf/1803.09820.pdf).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytg-0FTHG7ik",
        "colab_type": "code",
        "outputId": "fddc7b6a-f28a-49e6-c2c8-482c2e801d7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "learner.fit_onecycle(2e-5, 4)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "Train on 11314 samples\n",
            "Epoch 1/4\n",
            "11314/11314 [==============================] - 971s 86ms/sample - loss: 1.3191 - accuracy: 0.6241\n",
            "Epoch 2/4\n",
            "11314/11314 [==============================] - 954s 84ms/sample - loss: 0.3826 - accuracy: 0.8821\n",
            "Epoch 3/4\n",
            "11314/11314 [==============================] - 956s 84ms/sample - loss: 0.1655 - accuracy: 0.9494\n",
            "Epoch 4/4\n",
            "11314/11314 [==============================] - 955s 84ms/sample - loss: 0.0501 - accuracy: 0.9873\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2ce1501550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMySkTNDSyyM",
        "colab_type": "text"
      },
      "source": [
        "We can use the `learner.validate` method to test our model against the validation set.\n",
        "As we can see, BERT achieves a **96%** accuracy, which is quite a bit higher than the 91% accuracy achieved by SVM in the [scikit-learn tutorial](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ4beXIyHdYB",
        "colab_type": "code",
        "outputId": "53c23446-55a2-4840-d100-d74a0bfcb2d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learner.validate(val_data=(x_test, y_test), class_names=train_b.target_names)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alt.atheism       0.80      0.78      0.79       319\n",
            "           comp.graphics       0.84      0.81      0.82       389\n",
            " comp.os.ms-windows.misc       0.83      0.84      0.83       394\n",
            "comp.sys.ibm.pc.hardware       0.78      0.82      0.80       392\n",
            "   comp.sys.mac.hardware       0.83      0.87      0.85       385\n",
            "          comp.windows.x       0.90      0.92      0.91       395\n",
            "            misc.forsale       0.91      0.92      0.92       390\n",
            "               rec.autos       0.94      0.90      0.92       396\n",
            "         rec.motorcycles       0.92      0.92      0.92       398\n",
            "      rec.sport.baseball       0.97      0.94      0.96       397\n",
            "        rec.sport.hockey       0.96      0.98      0.97       399\n",
            "               sci.crypt       0.93      0.94      0.94       396\n",
            "         sci.electronics       0.85      0.82      0.84       393\n",
            "                 sci.med       0.94      0.93      0.94       396\n",
            "               sci.space       0.91      0.94      0.93       394\n",
            "  soc.religion.christian       0.91      0.95      0.93       398\n",
            "      talk.politics.guns       0.73      0.84      0.78       364\n",
            "   talk.politics.mideast       0.98      0.90      0.94       376\n",
            "      talk.politics.misc       0.70      0.61      0.65       310\n",
            "      talk.religion.misc       0.70      0.72      0.71       251\n",
            "\n",
            "                accuracy                           0.87      7532\n",
            "               macro avg       0.87      0.87      0.87      7532\n",
            "            weighted avg       0.87      0.87      0.87      7532\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[248,   1,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,\n",
              "          2,   7,  14,   0,   0,  10,  36],\n",
              "       [  0, 315,  14,   7,   9,  18,   1,   0,   0,   0,   1,  14,   4,\n",
              "          0,   4,   2,   0,   0,   0,   0],\n",
              "       [  0,  18, 331,  21,   7,  10,   0,   0,   1,   0,   0,   0,   1,\n",
              "          1,   0,   0,   0,   0,   4,   0],\n",
              "       [  0,   9,  26, 320,  17,   2,   7,   0,   2,   0,   0,   2,   6,\n",
              "          0,   0,   1,   0,   0,   0,   0],\n",
              "       [  0,   2,   3,  31, 334,   1,   7,   0,   0,   0,   0,   1,   6,\n",
              "          0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,  10,  18,   0,   1, 362,   2,   0,   0,   0,   0,   0,   1,\n",
              "          1,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   2,   3,   4,  10,   1, 358,   0,   3,   0,   0,   1,   6,\n",
              "          0,   1,   1,   0,   0,   0,   0],\n",
              "       [  0,   0,   3,   0,   1,   0,   8, 355,  12,   0,   0,   0,  12,\n",
              "          0,   1,   0,   0,   0,   3,   1],\n",
              "       [  1,   1,   0,   0,   0,   0,   2,  12, 368,   0,   1,   1,   6,\n",
              "          1,   2,   0,   1,   0,   1,   1],\n",
              "       [  1,   0,   0,   0,   0,   0,   1,   1,   2, 374,  11,   0,   0,\n",
              "          1,   0,   1,   3,   0,   1,   1],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   1,   1,   4, 391,   0,   1,\n",
              "          1,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   2,   0,   0,   1,   1,   1,   0,   0,   4,   0, 371,   5,\n",
              "          0,   2,   0,   3,   1,   5,   0],\n",
              "       [  0,   3,   1,  23,  14,   2,   4,   7,   2,   0,   0,   1, 322,\n",
              "         11,   3,   0,   0,   0,   0,   0],\n",
              "       [  2,   5,   0,   0,   1,   0,   0,   0,   1,   0,   0,   0,   5,\n",
              "        369,   1,   5,   0,   1,   6,   0],\n",
              "       [  6,   6,   0,   0,   3,   0,   1,   0,   0,   0,   1,   0,   2,\n",
              "          1, 371,   0,   0,   1,   2,   0],\n",
              "       [  6,   2,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          2,   0, 377,   0,   0,   0,  10],\n",
              "       [  0,   0,   0,   0,   1,   0,   0,   0,   1,   0,   1,   1,   0,\n",
              "          0,   3,   0, 307,   0,  31,  19],\n",
              "       [  9,   0,   0,   2,   1,   2,   0,   0,   1,   1,   0,   2,   0,\n",
              "          0,   0,   1,   2, 337,  15,   3],\n",
              "       [  2,   0,   0,   0,   0,   2,   0,   0,   1,   1,   0,   3,   0,\n",
              "          2,   6,   1,  96,   2, 189,   5],\n",
              "       [ 36,   0,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,\n",
              "          1,   5,  11,   9,   2,   4, 181]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdBJBZl8TqkR",
        "colab_type": "text"
      },
      "source": [
        "## How to Use Our Trained BERT Model\n",
        "\n",
        "We can call the `learner.get_predictor` method to obtain a Predictor object capable of making predictions on new raw data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCPyMtk3L1qR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor = ktrain.get_predictor(learner.model, preproc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcnpWw0oSUwb",
        "colab_type": "code",
        "outputId": "8220f0c8-9cd1-43a4-e954-1ecf5d734ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "predictor.get_classes()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEtfzxqzSW_k",
        "colab_type": "code",
        "outputId": "2ff6fe48-a4b9-4a93-cb18-47591ff369f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictor.predict(test_b.data[0:1])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rec.autos']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvaTCPafSrtT",
        "colab_type": "code",
        "outputId": "30b921bf-7c83-433a-d0f2-674826f00777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "# we can visually verify that our prediction of 'sci.med' for this document is correct\n",
        "print(test_b.data[0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. GANDLER)\n",
            "Subject: Need info on 88-89 Bonneville\n",
            "Organization: University at Buffalo\n",
            "Lines: 10\n",
            "News-Software: VAX/VMS VNEWS 1.41\n",
            "Nntp-Posting-Host: ubvmsd.cc.buffalo.edu\n",
            "\n",
            "\n",
            " I am a little confused on all of the models of the 88-89 bonnevilles.\n",
            "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
            "differences are far as features or performance. I am also curious to\n",
            "know what the book value is for prefereably the 89 model. And how much\n",
            "less than book value can you usually get them for. In other words how\n",
            "much are they in demand this time of year. I have heard that the mid-spring\n",
            "early summer is the best time to buy.\n",
            "\n",
            "\t\t\tNeil Gandler\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvEfCWmIUdw6",
        "colab_type": "code",
        "outputId": "7ece7492-e292-4f3b-cb5d-96dbb37a9444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# we predicted the correct label\n",
        "print(test_b.target_names[test_b.target[0]])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rec.autos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cStbMM0Uv48d",
        "colab_type": "text"
      },
      "source": [
        "The `predictor.save` and `ktrain.load_predictor` methods can be used to save the Predictor object to disk and reload it at a later time to make predictions on new data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJCmD8lNSvN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's save the predictor for later use\n",
        "predictor.save('/tmp/my_predictor')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAdRe_3bar3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reload the predictor\n",
        "reloaded_predictor = ktrain.load_predictor('/tmp/my_predictor')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHXgnfulazvQ",
        "colab_type": "code",
        "outputId": "a3cbe24c-feca-4e02-f3b0-ac4dd11b9be6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# make a prediction on the same document to verify it still works\n",
        "reloaded_predictor.predict(test_b.data[0:1])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rec.autos']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    }
  ]
}